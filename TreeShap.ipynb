{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names = pd.read_csv(\"/Users/kritinshanmugam/Desktop/names.csv\", header=None)\n",
    "names_list = names.iloc[:, 0].tolist()\n",
    "\n",
    "X = pd.read_csv(\"/Users/kritinshanmugam/Desktop/genes.csv\", header=None, names=names_list)\n",
    "y = pd.read_csv(\"/Users/kritinshanmugam/Desktop/labels.csv\", header=None, names = ['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0610007P14Rik  0610009B22Rik  0610009L18Rik  0610009O20Rik  0610010F05Rik  \\\n",
      "0       6.357779      -0.129192      -0.133012      -0.339486      -0.441585   \n",
      "1      -0.177072      -0.129192      -0.133012      -0.339486      -0.441585   \n",
      "2      -0.177072      -0.129192      -0.133012      -0.339486      -0.441585   \n",
      "3      -0.177072      -0.129192      -0.133012      -0.339486      -0.441585   \n",
      "4      -0.177072      -0.129192      -0.133012      -0.339486      -0.441585   \n",
      "\n",
      "   0610012D04Rik  0610012G03Rik  0610025J13Rik  0610030E20Rik  0610031O16Rik  \\\n",
      "0      -0.048584      -0.218664      -0.071389      -0.290955      -0.011646   \n",
      "1      -0.048584      -0.218664      -0.071389      -0.290955      -0.011646   \n",
      "2      -0.048584      -0.218664      -0.071389      -0.290955      -0.011646   \n",
      "3      -0.048584      -0.218664      -0.071389      -0.290955      -0.011646   \n",
      "4      -0.048584      -0.218664      -0.071389      -0.290955      -0.011646   \n",
      "\n",
      "   ...    mt-Co2    mt-Co3   mt-Cytb    mt-Nd1    mt-Nd2    mt-Nd3    mt-Nd4  \\\n",
      "0  ... -0.938403  1.116733  0.888012 -0.621394  0.884904  1.569081  0.672020   \n",
      "1  ... -0.938403 -1.068803 -0.650131 -0.621394 -0.629571 -0.466758 -0.708458   \n",
      "2  ... -0.938403  1.404054 -0.650131 -0.621394 -0.629571 -0.466758  0.826897   \n",
      "3  ...  1.498860  0.828810  0.985457 -0.621394  0.980850 -0.466758  0.759477   \n",
      "4  ...  1.390940  1.740110 -0.650131 -0.621394 -0.629571 -0.466758  1.058776   \n",
      "\n",
      "    mt-Nd4l    mt-Nd5    mt-Nd6  \n",
      "0 -0.260147 -0.428012 -0.133387  \n",
      "1 -0.260147 -0.428012 -0.133387  \n",
      "2 -0.260147  1.918965 -0.133387  \n",
      "3 -0.260147 -0.428012 -0.133387  \n",
      "4 -0.260147 -0.428012 -0.133387  \n",
      "\n",
      "[5 rows x 21215 columns]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Handle missing values\n",
    "X = X.dropna()\n",
    "y = y.dropna()\n",
    "\n",
    "# Standardize features\n",
    "X = (X - X.mean()) / X.std()\n",
    "\n",
    "# Create copy of original (untransformed) y data to compare later with predictions\n",
    "y_orig = y.copy()\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "[(XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), 0.8707607699358386), (XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...), 0.8797814207650273)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "'''\n",
    "# Create list to store incorrect predictions\n",
    "xg_incorrect = []\n",
    "\n",
    "for row in range(len(xg_preds)):\n",
    "    if xg_preds.iloc[row, 0] != y_test.iloc[row, 0]:\n",
    "        xg_incorrect.append(row)\n",
    "        \n",
    "print(len(xg_incorrect))\n",
    "'''\n",
    "\n",
    "# List to store each XGBoost model\n",
    "models = []\n",
    "\n",
    "\n",
    "# Create 100 models, train on 90% of dataset, find model with lowest score\n",
    "for i in range(2):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    # Create temporary XGBoost instance\n",
    "    temp_model = XGBClassifier()\n",
    "    \n",
    "    # Split into 90% training, 10% test\n",
    "    t_x_train, t_x_test, t_y_train, t_y_test = train_test_split(X, y, test_size=0.1)\n",
    "    \n",
    "    t_y_test = pd.DataFrame(t_y_test)\n",
    "    actual = t_y_test.values\n",
    "    \n",
    "    # Train the model\n",
    "    temp_model.fit(t_x_train, t_y_train)\n",
    "    \n",
    "    # Predict based on x_test\n",
    "    temp_pred = temp_model.predict(t_x_test)\n",
    "    temp_pred = pd.DataFrame(temp_pred)\n",
    "    \n",
    "    # Get F1 score\n",
    "    temp_f1 = f1_score(actual, temp_pred.values)\n",
    "    \n",
    "    # Add the model to the list for storage\n",
    "    models.append((temp_model, temp_f1))\n",
    "    \n",
    "\n",
    "sorted_models = sorted(models, key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fy/m0zjz52x4kb7hwy0z4jxwk5r0000gn/T/ipykernel_35241/1071011410.py:17: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  mis_temp = np.sum(temp_ar != np.array(y), axis = 0)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "optimal_hundred = sorted_models[:99]\n",
    "\n",
    "optimal_predictions = []\n",
    "for model in optimal_hundred:\n",
    "    pred = model.predict(X)\n",
    "    optimal_predictions.append(pred)\n",
    "\n",
    "pred_array = np.array(optimal_predictions)\n",
    "mispredicted_count = np.sum(pred_array != np.array(y), axis=0)\n",
    "bad_points = np.where(mispredicted_count > 50)[0]\n",
    "'''\n",
    "\n",
    "temp = [[1,2,3], [1,3,1], [1,6,1]]\n",
    "temp_real = [1,1,1]\n",
    "temp_ar = np.array(temp)\n",
    "mis_temp = np.sum(temp_ar != np.array(y), axis = 0)\n",
    "bad_temp = np.where(mis_temp > 50)[0]\n",
    "print(bad_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Get the actual values and predicted values in array-like format\n",
    "actual = y_test.values\n",
    "\n",
    "predicted = xg_preds.values\n",
    "\n",
    "# Generate a confusion matrix\n",
    "confusion = confusion_matrix(actual, predicted, labels=xg_classifier.classes_) \n",
    "\n",
    "# Generate display for confusion matrix\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=xg_classifier.classes_)\n",
    "\n",
    "display.plot()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.TreeExplainer(classifier, x_test)\n",
    "shap_values = explainer(x_test)\n",
    "\n",
    "for row in incorrect_list:\n",
    "    shap.plots.waterfall(shap_values[row])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
