{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# function to find the key of the value when label encoding the classes\n",
    "def key_find(classes, pred):\n",
    "    for key, val in classes.items():\n",
    "        if pred == val:\n",
    "            return key\n",
    "        \n",
    "        \n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# get data and instantiate Random Forest Classifier\n",
    "X = pd.read_csv(\"/Users/kritinshanmugam/Desktop/gene_expression.csv\")\n",
    "y = pd.read_csv(\"/Users/kritinshanmugam/Desktop/label.csv\")\n",
    "\n",
    "classifier = RandomForestClassifier(random_state=31)\n",
    "\n",
    "# Handle missing values\n",
    "X = X.dropna()\n",
    "y = y.dropna()\n",
    "\n",
    "# Drop ID column\n",
    "X.drop(columns=X.columns[0], axis=1)\n",
    "\n",
    "# Standardize features\n",
    "X = (X - X.mean()) / X.std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y.drop(columns=y.columns[0], axis=1)\n",
    "\n",
    "y_orig = y.copy()\n",
    "\n",
    "# One-hot encode the target variable\n",
    "y = pd.DataFrame(label_encoder.fit_transform(y))\n",
    "\n",
    "# Print the mapping between original classes and encoded integers\n",
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "# Split the data into train and test sets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "x_train = X.iloc[500:, :]\n",
    "x_test = X.iloc[0:500, :]\n",
    "\n",
    "y_train = y.iloc[500:]\n",
    "y_test = y.iloc[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(x_train, y_train)\n",
    "y_predictions = classifier.predict(x_test)\n",
    "\n",
    "predicted = pd.DataFrame({'predicted_class': []})\n",
    "\n",
    "\n",
    "for prediction in y_predictions:\n",
    "    class_pred = key_find(class_mapping, prediction)\n",
    "    predicted.loc[len(predicted)] = class_pred\n",
    "\n",
    "incorrect_list = []\n",
    "\n",
    "for row in range(len(predicted)):\n",
    "    if predicted.iloc[row, 0] != y_orig.iloc[row, 0]:\n",
    "        incorrect_list.append(row)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explaine = shap.TreeExplainer(model)\n",
    "shap_values = explaine.shap_values(X)\n",
    "row = 1\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[0][row],\n",
    "                                     base_values=explaine.expected_value[0], data=x_test.iloc[row],\n",
    "                                     feature_names=x_test.columns.tolist()))\n",
    "\n",
    "shap.plots.waterfall(shap_values[0][row])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
