{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# function to find the key of the value when label encoding the classes\n",
    "def key_find(classes, pred):\n",
    "    for key, val in classes.items():\n",
    "        if pred == val:\n",
    "            return key\n",
    "        \n",
    "        \n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# get data and instantiate Random Forest Classifier\n",
    "X = pd.read_csv(\"/Users/kritinshanmugam/Desktop/gene_expression.csv\")\n",
    "y = pd.read_csv(\"/Users/kritinshanmugam/Desktop/label.csv\")\n",
    "\n",
    "# Handle missing values\n",
    "X = X.dropna()\n",
    "y = y.dropna()\n",
    "\n",
    "# Drop ID column\n",
    "X.drop(columns=X.columns[0], axis=1)\n",
    "\n",
    "# Standardize features\n",
    "X = (X - X.mean()) / X.std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the first column of cell ID\n",
    "y.drop(columns=y.columns[0], axis=1)\n",
    "\n",
    "# Create copy of original (untransformed) y data to compare later with predictions\n",
    "y_orig = y.copy()\n",
    "\n",
    "# One-hot encode the target variable\n",
    "y = pd.DataFrame(label_encoder.fit_transform(y))\n",
    "\n",
    "# Print the mapping between original classes and encoded integers\n",
    "class_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "\n",
    "\n",
    "# Combine data sets for ease of splitting into train and test data sets\n",
    "combined_XY = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train, test = train_test_split(combined_XY, test_size=0.25, stratify=y['Time point'])\n",
    "\n",
    "# Get the train/test data for the features\n",
    "x_train = train.drop(columns=['Time Point', 'Annotation'], axis=1)\n",
    "x_test = test.drop(columns=['Time Point', 'Annotation'], axis=1)\n",
    "\n",
    "# Get the train/test data for the target \n",
    "y_train = train['Annotation']\n",
    "y_test = test['Annotation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the random forest model\n",
    "classifier = RandomForestClassifier(random_state=31)\n",
    "\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Obtain the predictions\n",
    "y_predictions = classifier.predict(x_test)\n",
    "\n",
    "# parameters for the model\n",
    "params = {\n",
    "    'n_estimators': [200, 600, 1_000, 1_400, 1_800],\n",
    "    'max_depth': [3, 5, 7, 10, 13],\n",
    "    'min_sample_split': [2, 5, 8, 11, 14, 17],\n",
    "    'min_sample_leaf' : [2, 4, 6, 8],\n",
    "    'max_features': [2, 4, 6, 8]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate an empty dataframe to store the predictions in pre-transform format\n",
    "predicted = pd.DataFrame({'predicted_class': []})\n",
    "\n",
    "# Loop through the predictions and transform them back from the binary state\n",
    "for prediction in y_predictions:\n",
    "    class_pred = key_find(class_mapping, prediction)\n",
    "    predicted.loc[len(predicted)] = class_pred\n",
    "\n",
    "# Create list to store rows that have mispredicted cell types\n",
    "incorrect_list = []\n",
    "\n",
    "for row in range(len(predicted)):\n",
    "    if predicted.iloc[row, 0] != y_orig.iloc[row, 0]:\n",
    "        incorrect_list.append(row)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "explaine = shap.TreeExplainer(model)\n",
    "shap_values = explaine.shap_values(X)\n",
    "row = 1\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[0][row],\n",
    "                                     base_values=explaine.expected_value[0], data=x_test.iloc[row],\n",
    "                                     feature_names=x_test.columns.tolist()))\n",
    "\n",
    "shap.plots.waterfall(shap_values[0][row])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
